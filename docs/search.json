[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Blog",
    "section": "",
    "text": "Welcome to my blog! I primarily talk about datascience here. Ive just posted my first blogpost below!:\n\nTest2"
  },
  {
    "objectID": "Fast development & deployment of deep learning applications.html",
    "href": "Fast development & deployment of deep learning applications.html",
    "title": "Fast development & deployment of deep learning applications",
    "section": "",
    "text": "After not having touched machine learning, or deep learning & AI in any developmental capacity for quite some time, personal and professional projects made it the opportune moment to go back and get the back catalog actually published.\nThat is what this blogpost is for! here, i am going to take a beginners view to deep learning & AI, and present it in as accessible a format as possible - the goal is that you should be able to follow along the major concepts with only minimal coding or machine learning knowledge.\nWhile AI and deep learning can seem intimidating, a majority of the complexity is to be found in the attempts to optimize the training process itself computationally. The main task and ideas of deep learning i hold - are very easy to grasp. The deep learning community also owes a great deal to the opensource spirit of thousands of practitioners around the world, who have made som very, very powerful tools that we will be using today.\nWith those tools, we will be able to achieve very much, with very little code, as you will see soon.\nFirst, a little theory around deep learning & transfer learning are in order, however. Feel free to skip it if you dont feel you need the reminder!"
  },
  {
    "objectID": "Fast development & deployment of deep learning applications.html#hello",
    "href": "Fast development & deployment of deep learning applications.html#hello",
    "title": "Fast development & deployment of deep learning applications",
    "section": "",
    "text": "After not having touched machine learning, or deep learning & AI in any developmental capacity for quite some time, personal and professional projects made it the opportune moment to go back and get the back catalog actually published.\nThat is what this blogpost is for! here, i am going to take a beginners view to deep learning & AI, and present it in as accessible a format as possible - the goal is that you should be able to follow along the major concepts with only minimal coding or machine learning knowledge.\nWhile AI and deep learning can seem intimidating, a majority of the complexity is to be found in the attempts to optimize the training process itself computationally. The main task and ideas of deep learning i hold - are very easy to grasp. The deep learning community also owes a great deal to the opensource spirit of thousands of practitioners around the world, who have made som very, very powerful tools that we will be using today.\nWith those tools, we will be able to achieve very much, with very little code, as you will see soon.\nFirst, a little theory around deep learning & transfer learning are in order, however. Feel free to skip it if you dont feel you need the reminder!"
  },
  {
    "objectID": "Fast development & deployment of deep learning applications.html#deep-learning-neural-nets-transfer-learning",
    "href": "Fast development & deployment of deep learning applications.html#deep-learning-neural-nets-transfer-learning",
    "title": "Fast development & deployment of deep learning applications",
    "section": "Deep learning, neural nets & Transfer learning",
    "text": "Deep learning, neural nets & Transfer learning\nAlmost all of the most advanced machine learning models today rely on a special architecture called a neural net. Among these are - ALL LLM chatbots(ChatGPT, Gemini, LLama, Claude). Most computer visions tasks(x-ray diagnostics, object recognition) and recommender systems(Spotify, Netflix) The neural net is ofcourse, inspired by the human brain, and its vast interconnectivity. A brain has neurons, and so a neural net’s optimizable parameters are also called neurons, to honor this inspiration.\nThis analogy to the human brain is fine - and not wrong. However, i find that it leads alot of misconceptions about neural nets when left on its own because of one very important misunderstanding. And that is, that unlike the human brain, neural nets (atleast on their own, it seems) CANNOT do the amazingly huge array of problem solving that we humans can do. Even if amazing, i implore you to always remember:\nA neural net, is a machine learning model that predicts things - just like any other machine learning model! It just uses a neural architecture to solve very specific problems. This is even the case for the most advanced AI systems in the world today, like the generate chatbots, which i would like to explain in a later post.\n\n\n\nA neural net\n\n\nWhat makes a neural net special I feel is best understood in comparison, so let us take what is probably the most well known model, the regression model as an example.\nLet’s try to predict apple sales price from a variety of factors, (height, weight, harvesting time) In a regression model, apple sales price would be our dependent variable, and the apple attributes (height, weight, harvesting time) the indepdent variables - the ones we use to predict the dependent variable with. To find out how important (or unimportant) each independent variable is on our apple sales price however, we need to train our model.\nTraining a model i find, is often one of the most confused parts of machine learning for any outsider or beginner - fraught with mythologizing assumptions and preconceptions around what it is, and how you do it.\nIn purely practical terms however, training is really very simple - both for regression AND for neural nets. Training, is about tweaking the value of the independent variables, to better predict the dependent variable. That’s it.\nFor regression, the most common algorithm used is called ordinary least squares. And after running that, we would be able to see the value or weight, the singular independent variable has.\nFor a neural net, the process would be largely the same. However, the one important distinction is the nature of the independent variables. For the regression model, we would specify each variable explicitly “this is how much height contributes to salesprice” With a neural net, we would instead make an arbitrary amount of “blank” or arbitrary weights, that dont correspond to anything specific at all at first.\nWe then use an algorithm called backpropagation (just like we used OLS for regression). Using backpropagation, we optimize these initial weights to make our predictions more accurate.\nSo in summary - for most models, we specify which characteristics we want to look at and optimize. For neural nets, we make the machine “find out” which parameters mean what."
  },
  {
    "objectID": "Fast development & deployment of deep learning applications.html#building-our-model",
    "href": "Fast development & deployment of deep learning applications.html#building-our-model",
    "title": "Fast development & deployment of deep learning applications",
    "section": "Building our model",
    "text": "Building our model\nThe task we are tackling today, is image recognition, which is something that was almost impossible just ten years ago before deep learning had made some more advancements. We are going to be making a classifier model to detect a range of animals.\nThe first thing we are going to do, is to set up our environment. You can do this yourself, running it on your own machine or a Linux server. For this demonstration i am going to be using an online environment, which is probably the easiest. The benefits are both time saving - as their environment comes with all the packages you might need. But they also provide computation on demand! Most services give you a set quota per week, but it is often generous enough for several small projects like this!\nI choose Kaggle as mine, but Google colab is another excellent option.\nSetup:\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n\nprint(\"Path to dataset files:\", path)\n\nFirst we download and set a path to the kaggle environment for our chosen dataset.\n\nimport fastai\nimport pathlib\nimport streamlit as st\nfrom fastai.vision.all import *\nfrom fastai.learner import load_learner\nfrom PIL import ImageOps\nfrom io import BytesIO\n\nAfter we have our imports, we now have our dataset in our environment. The next step, is preparing the data to get loaded into our deep learning model. We are using fast.AI’s dataloaders functionality. This provides us with a huge range of functionality for loading our data, but also orchestrates it in away suitable for learning. This is called batching. Here is a sample of the images we have loaded in:\n\n# Create DataLoaders\ndls = dblock.dataloaders(path)\n\n# Show a batch of images\ndls.show_batch(max_n=9, figsize=(6,6))\n\n\n\n\nThe output of our batch\n\n\nA lot happened here in just 1 line - first, fastAI was able to take the pathobject, containing the path to our files. Then it’s converted that into suitable batches which are just about ready for training. Also, dont worry about the italian labels - we can change them later when we actually display our app!\nNext, we are ready to train our model!\nWhat we are going to be doing, is transfer learning. This is a technique in which we take an existing deep learning model that has been pretrained (usually on enormous amounts of data) and then use our dataset to only only train or “fine tune” a very small portion of the model - usually the end, which is known as the head of the model.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(6)\n\nAs variables we input our dataloaders, and then resnet18 - which is a state of the art image recognition model. We then fine-tune for 6 epochs, which are 6 runs throug the entire dataset.\n![Training metrics(images/trainingdata.PNG)\nOur model performs exceedingly well, achieving an error rate of 2,44% after just six epochs, corresponding to an overall model accuracy of 97,56%\nWe can check which combinations that the model is having trouble with with a confusion matrix\n\ninterp = ClassificationInterpretation.from_learner(learn)\n\ninterp.plot_confusion_matrix()\n\n\n\n\nConfusion matrix - the actual labels are on the Y axis, the predictions on the X axis.\n\n\nThis is already really good. We can take a look at what the parts the machine struggled with the most\n\ninterp.plot_top_losses(8, nrows=1)\n\n\n\n\nA plot of the greatest contributors to the loss of our model\n\n\nThe image aboce shows what our model predicted is in the image, and the label, followed by the loss, and the probability or how sure the model was of its prediction.\nAs we can see, the very first image it does get wrong, believing it is a butterfly when it is in actuality a spider. However, many of the other top images, are clearly labeled incorrectly. Such as number 2, which is labeled as squirrel, or number 3, which is labeled cow! Even if the dog does look a bit squirrellike if you ask me, mislabelings like this are not helpful, and should really be removed!\nWe can clean our data by manually removing incorrected items like this (or relabeling), or even automated label verification, using another model to authenticate label accuracy!\nWorking with data like this, and ensuring accuracy and precision in what you feed your models, is really the most important part of deep learning, as so many amazing pre-trained models exist already for almost any purpose.\nWith that said, our model is complete and we can export it\n\n#Model export\nlearn.export()\npath = Path()\npath.ls(file_exts='.pkl')\n\nNow we are ready for deployment! If you are like me, and like to see rapid results, there are a great many options for fast deployment of models and python code. We are going to be using streamlit\n\nFirst, we write a short introduction to our app, welcoming visitors\n\n\n# Preamble\nst.title(\"Animal Classifier App\")\nst.write(\"\"\"\nThis application uses a fine-tuned **ResNet-18** model to classify images into 10 different animal categories. \nThe model has been trained on a dataset of animal images, and it predicts with high confidence for known categories.\n\"\"\")\n\nNext, we can finally do something about the italian labeling! so we create a simple python dictionary, and use it to map the labels to their corresponding english counterpart.\n\n# Display the animal categories\nst.subheader(\"Animal Categories\")\nname_mapping = {\n    'cavallo': 'horse',\n    'pecora': 'sheep',\n    'elefante': 'elephant',\n    'gatto': 'cat',\n    'scoiattolo': 'squirrel',\n    'gallina': 'chicken',\n    'ragno': 'spider',\n    'mucca': 'cow',\n    'cane': 'dog',\n    'farfalla': 'butterfly'\n}\nst.write(\", \".join([f\"**{v}**\" for v in name_mapping.values()]))\nst.write(\"\"\"\nUpload an image of an animal to see the classifier in action!\n\"\"\")\n\nNow we import our model, and use streamlits library to make a widget for uploading files\nEXPORT_PATH = pathlib.Path(“model3.pkl”) # Define the path to your model\nlearn_inf = load_learner(EXPORT_PATH) # Load the learner\nuploaded_file = st.file_uploader(“Choose an image…”, type=[“jpg”, “jpeg”, “png”])\nWe are almost there! now all we need to do, is to pass the image into our model and show the predictions. We also do some error handling, to make sure that we only accept images without crashing\n\nimg = None\n\nif uploaded_file:\n    try:\n        # Read and process the uploaded image\n        file_bytes = BytesIO(uploaded_file.read())\n        img = PILImage.create(file_bytes)\n        img = ImageOps.fit(img, (224, 224))  # Resize if necessary\n        st.image(img.to_thumb(256, 256), caption=\"Uploaded Image\")\n\n        # Make prediction\n        pred_class, pred_idx, probs = learn_inf.predict(img)\n        # Map the predicted class to its English label\n        english_label = name_mapping.get(pred_class, pred_class)  # Fallback to original if not in mapping\n        st.write(f\"Prediction: {english_label}\")\n        st.write(f\"Confidence: {probs[pred_idx]:.2f}\")\n\n    except Exception as e:\n        st.error(f\"Error during prediction: {e}\")\nelse:\n    st.warning(\"Please upload an image to classify.\")\n\nAnd that’s it! You’ve now made your very own image classifier in a minimum of steps.\nIf you want to host your project, you have to create a github repository, and add your project as a .py file, along with your model and a requirements.txt to handle the dependencies of the project!\nI have a demonstration live here: https://spvao5wuyengcgcebunrqs.streamlit.app/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Animal Classifier Webapp.html",
    "href": "Animal Classifier Webapp.html",
    "title": "Kristian Lauridsen Blog",
    "section": "",
    "text": "pip install fastai torch --upgrade\n\nRequirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.18)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\nCollecting torch\n  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.2)\nRequirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore&lt;1.8,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.7.19)\nRequirement already satisfied: torchvision&gt;=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.20.0+cu121)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.8.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.2.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.32.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.2)\nRequirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\nRequirement already satisfied: pillow&gt;=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (11.0.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.13.1)\nRequirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions&gt;=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.1.0 (from torch)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1-&gt;torch) (1.3.0)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.5)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.10)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (2.0.8)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (3.0.9)\nRequirement already satisfied: thinc&lt;8.3.0,&gt;=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (8.2.5)\nRequirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (1.1.3)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (2.4.8)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (2.0.10)\nRequirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (0.4.1)\nRequirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (0.13.0)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (4.66.6)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (2.9.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (75.1.0)\nRequirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (3.4.1)\nRequirement already satisfied: numpy&gt;=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai) (1.26.4)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;fastai) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;fastai) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;fastai) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;fastai) (2024.8.30)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (3.0.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (1.3.0)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (4.54.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (1.4.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (3.2.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;fastai) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;fastai) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;fastai) (2024.2)\nRequirement already satisfied: joblib&gt;=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;fastai) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;fastai) (3.5.0)\nRequirement already satisfied: language-data&gt;=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;4-&gt;fastai) (1.2.0)\nRequirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;4-&gt;fastai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;4-&gt;fastai) (2.23.4)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;fastai) (1.16.0)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;4-&gt;fastai) (0.7.11)\nRequirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;4-&gt;fastai) (0.1.5)\nRequirement already satisfied: click&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (8.1.7)\nRequirement already satisfied: shellingham&gt;=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (1.5.4)\nRequirement already satisfied: rich&gt;=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (13.9.4)\nRequirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (0.20.0)\nRequirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (7.0.5)\nRequirement already satisfied: marisa-trie&gt;=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;4-&gt;fastai) (1.2.1)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (0.1.2)\n\n\n\nfrom ipywidgets import widgets\nfrom fastai.vision.widgets import *\nfrom types import SimpleNamespace\nfrom fastai.vision.core import PILImage\nfrom fastai.learner import load_learner\n\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\nname_mapping = {\n    'cavallo': 'horse',\n    'pecora': 'sheep',\n    'elefante': 'elephant',\n    'gatto': 'cat',\n    'scoiattolo': 'squirrel',\n    'gallina': 'chicken',\n    'ragno': 'spider',\n    'mucca': 'cow',\n    'cane': 'dog',\n    'farfalla': 'butterfly'\n}\n\n# Function to get the English label from the folder name\ndef get_english_label(filepath):\n    folder_name = filepath.parent.name\n    return name_mapping.get(folder_name, folder_name)  # Default to original if not in mapping\n\n\nimport os\n\n# Create a directory in Colab's file system\nos.makedirs('/content/my_data', exist_ok=True)\n\n# Alternatively, create a directory in Google Drive\nos.makedirs('/content/drive/My Drive/my_data', exist_ok=True)\n\n\n#hide_output\nbtn_upload = widgets.FileUpload()\nbtn_upload\n\n\n\n\n\n\n#hide\n# For the book, we can't actually click an upload button, so we fake it\nbtn_upload = SimpleNamespace(data = ['catimage.jpg'])\n\n\nimg = PILImage.create(btn_upload.data[-1])\n\n\n#hide_output\nout_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(128,128))\nout_pl\n\n\n\n\n\nprint(os.listdir('/content/'))\n\n['.config', 'drive', 'model.pkl', 'catimage.jpg', 'my_data', 'sample_data']\n\n\n\nlearn_inf = load_learner('/content/models/export.pkl')\n\n\npred,pred_idx,probs = learn_inf.predict(img)\n\n\n\n\n\n\n\n\n\n#hide_output\nlbl_pred = widgets.Label()\nlbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\nlbl_pred\n\n\n\n\n\n#hide_output\nbtn_run = widgets.Button(description='Classify')\nbtn_run\n\n\n\n\n\ndef on_click_classify(change):\n    img = PILImage.create(btn_upload.data[-1])\n    out_pl.clear_output()\n    with out_pl: display(img.to_thumb(128,128))\n    pred,pred_idx,probs = learn_inf.predict(img)\n    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n\nbtn_run.on_click(on_click_classify)\n\n\n#hide\n#Putting back btn_upload to a widget for next cell\nbtn_upload = widgets.FileUpload()\n\n\n#hide_output\nVBox([widgets.Label('Select your bear!'),\n      btn_upload, btn_run, out_pl, lbl_pred])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollecting voila\n  Downloading voila-0.5.8-py3-none-any.whl.metadata (9.5 kB)\nCollecting jupyter-client&lt;9,&gt;=7.4.4 (from voila)\n  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: jupyter-core&gt;=4.11.0 in /usr/local/lib/python3.10/dist-packages (from voila) (5.7.2)\nRequirement already satisfied: jupyter-server&lt;3,&gt;=1.18 in /usr/local/lib/python3.10/dist-packages (from voila) (1.24.0)\nCollecting jupyterlab-server&lt;3,&gt;=2.3.0 (from voila)\n  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: nbclient&gt;=0.4.0 in /usr/local/lib/python3.10/dist-packages (from voila) (0.10.0)\nRequirement already satisfied: nbconvert&lt;8,&gt;=6.4.5 in /usr/local/lib/python3.10/dist-packages (from voila) (7.16.4)\nRequirement already satisfied: traitlets&lt;6,&gt;=5.0.3 in /usr/local/lib/python3.10/dist-packages (from voila) (5.7.1)\nCollecting websockets&gt;=9.0 (from voila)\n  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&lt;9,&gt;=7.4.4-&gt;voila) (2.8.2)\nRequirement already satisfied: pyzmq&gt;=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&lt;9,&gt;=7.4.4-&gt;voila) (24.0.1)\nRequirement already satisfied: tornado&gt;=6.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&lt;9,&gt;=7.4.4-&gt;voila) (6.3.3)\nRequirement already satisfied: platformdirs&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core&gt;=4.11.0-&gt;voila) (4.3.6)\nRequirement already satisfied: anyio&lt;4,&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (3.7.1)\nRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (23.1.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (3.1.4)\nRequirement already satisfied: nbformat&gt;=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (5.10.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (24.2)\nRequirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (0.21.0)\nRequirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (1.8.3)\nRequirement already satisfied: terminado&gt;=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (0.18.1)\nRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server&lt;3,&gt;=1.18-&gt;voila) (1.8.0)\nRequirement already satisfied: babel&gt;=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (2.16.0)\nCollecting json5&gt;=0.9.0 (from jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila)\n  Downloading json5-0.9.28-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: jsonschema&gt;=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (4.23.0)\nRequirement already satisfied: requests&gt;=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (4.12.3)\nRequirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (6.2.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (0.7.1)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (0.3.0)\nRequirement already satisfied: markupsafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (3.0.2)\nRequirement already satisfied: mistune&lt;4,&gt;=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (3.0.2)\nRequirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (1.5.1)\nRequirement already satisfied: pygments&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (2.18.0)\nRequirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (1.4.0)\nRequirement already satisfied: idna&gt;=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio&lt;4,&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (3.10)\nRequirement already satisfied: sniffio&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio&lt;4,&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio&lt;4,&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (1.2.2)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0-&gt;nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (0.5.1)\nRequirement already satisfied: attrs&gt;=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (24.2.0)\nRequirement already satisfied: jsonschema-specifications&gt;=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (2024.10.1)\nRequirement already satisfied: referencing&gt;=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (0.35.1)\nRequirement already satisfied: rpds-py&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (0.21.0)\nRequirement already satisfied: fastjsonschema&gt;=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat&gt;=5.2.0-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (2.20.0)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;jupyter-client&lt;9,&gt;=7.4.4-&gt;voila) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (3.4.0)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.3.0-&gt;voila) (2024.8.30)\nRequirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado&gt;=0.8.3-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (21.2.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;nbconvert&lt;8,&gt;=6.4.5-&gt;voila) (2.6)\nRequirement already satisfied: cffi&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings-&gt;argon2-cffi-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi&gt;=1.0.1-&gt;argon2-cffi-bindings-&gt;argon2-cffi-&gt;jupyter-server&lt;3,&gt;=1.18-&gt;voila) (2.22)\nDownloading voila-0.5.8-py3-none-any.whl (4.5 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 52.5 MB/s eta 0:00:00\nDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.1/106.1 kB 11.2 MB/s eta 0:00:00\nDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.7/59.7 kB 6.1 MB/s eta 0:00:00\nDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.2/168.2 kB 15.0 MB/s eta 0:00:00\nDownloading json5-0.9.28-py3-none-any.whl (30 kB)\nInstalling collected packages: websockets, json5, jupyter-client, jupyterlab-server, voila\n  Attempting uninstall: jupyter-client\n    Found existing installation: jupyter-client 6.1.12\n    Uninstalling jupyter-client-6.1.12:\n      Successfully uninstalled jupyter-client-6.1.12\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnotebook 6.5.5 requires jupyter-client&lt;8,&gt;=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\nSuccessfully installed json5-0.9.28 jupyter-client-8.6.3 jupyterlab-server-2.27.3 voila-0.5.8 websockets-14.1\nEnabling: voila\n- Writing config: /usr/etc/jupyter\n    - Validating...\n      voila 0.5.8 OK"
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = np.pi * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#polar-axis",
    "href": "hello.html#polar-axis",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = np.pi * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#hello",
    "href": "hello.html#hello",
    "title": "Quarto Basics",
    "section": "HELLO",
    "text": "HELLO\nHej med jer det her er en test, ser det også sick ud?"
  },
  {
    "objectID": "hello.html#test-i-realtidd",
    "href": "hello.html#test-i-realtidd",
    "title": "Quarto Basics",
    "section": "Test i REALTIDD!!!",
    "text": "Test i REALTIDD!!!"
  }
]