{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5ccbbfc-8fea-4dec-ba8f-86e2eae3af81",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Fast development & deployment of deep learning applications\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "description: \"A brief walkthrough of how to rapidly develop and deploy simple deep learning models, that are on par with the state of the art.\"\n",
    "author: \"Kristian Lauridsen \"\n",
    "date: \"2024-11-28\"\n",
    "categories: [first-post, data-science, deployment, fast-ai, pytorch]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7ee38-1375-44f5-ae21-728a66829c88",
   "metadata": {},
   "source": [
    "## Hello!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987116c-762c-4a27-a906-aea5fc49c112",
   "metadata": {},
   "source": [
    "After not having touched machine learning, or deep learning & AI in any developmental capacity for quite some time, personal and professional projects made it the opportune moment to go back and get the back catalog actually published."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fbd67-f28d-4dea-98f2-66e6016f8921",
   "metadata": {},
   "source": [
    "That is what this blogpost is for! here, i am going to take a beginners view to deep learning & AI, and present it in as accessible a format as possible - the goal is that you should be able to follow along the major concepts with only minimal coding or machine learning knowledge. \n",
    "\n",
    "While AI and deep learning can seem intimidating, a majority of the complexity is to be found in the attempts to optimize the training process itself computationally. The main task and ideas of deep learning i hold - are very easy to grasp. The deep learning community also owes a great deal to the opensource spirit of thousands of practitioners around the world, who have made som very, very powerful tools that we will be using today.\n",
    "\n",
    "With those tools, we will be able to achieve very much, with very little code, as you will see soon.\n",
    "\n",
    "First, a little theory around deep learning & transfer learning are in order, however. Feel free to skip it if you dont feel you need the reminder!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859c71f-28e1-4acc-8435-6d9d12da725c",
   "metadata": {},
   "source": [
    "## **Deep learning, neural nets & Transfer learning**\n",
    "\n",
    "Almost all of the most advanced machine learning models today rely on a special architecture called a neural net. Among these are - ALL LLM chatbots(ChatGPT, Gemini, LLama, Claude). Most computer visions tasks(x-ray diagnostics, object recognition) and recommender systems(Spotify, Netflix)\n",
    "The neural net is ofcourse, inspired by the human brain, and its vast interconnectivity. A brain has neurons, and so a neural net's optimizable parameters are also called neurons, to honor this inspiration.\n",
    "\n",
    "This analogy to the human brain is fine - and not wrong. However, i find that it leads alot of misconceptions about neural nets when left on its own because of one very important misunderstanding. And that is, that unlike the human brain, neural nets (atleast on their own, it seems) CANNOT do the amazingly huge array of problem solving that we humans can do. Even if amazing, i implore you to always remember:\n",
    "\n",
    "A neural net, is a machine learning model that predicts things - just like any other machine learning model! It just uses a neural architecture to solve very specific problems. This is even the case for the most advanced AI systems in the world today, like the generate chatbots, which i would like to explain in a later post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd9445-d78a-4994-9a3b-fc00560a93bc",
   "metadata": {},
   "source": [
    "![A neural net](images/network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695785cd-a5ee-41d5-8909-f87a7a83d7fc",
   "metadata": {},
   "source": [
    "What makes a neural net special I feel is best understood in comparison, so let us take what is probably the most well known model, the regression model as an example.\n",
    "\n",
    "Let's try to predict apple sales price from a variety of factors, (height, weight, harvesting time)\n",
    "In a regression model, apple sales price would be our dependent variable, and the apple attributes (height, weight, harvesting time) the indepdent variables - the ones we use to predict the dependent variable with.\n",
    "To find out how important (or unimportant) each independent variable is on our apple sales price however, we need to train our model.\n",
    "\n",
    "Training a model i find, is often one of the most confused parts of machine learning for any outsider or beginner - fraught with mythologizing assumptions and preconceptions around what it is, and how you do it.\n",
    "\n",
    "In purely practical terms however, training is really very simple - both for regression AND for neural nets. Training, is about tweaking the value of the independent variables, to better predict the dependent variable. That's it.\n",
    "\n",
    "For regression, the most common algorithm used is called ordinary least squares. And after running that, we would be able to see the value or weight, the singular independent variable has.\n",
    "\n",
    "For a neural net, the process would be largely the same. However, the one important distinction is the nature of the independent variables. For the regression model, we would specify each variable explicitly \"this is how much height contributes to salesprice\" With a neural net, we would instead make an arbitrary amount of \"blank\" or arbitrary weights, that dont correspond to anything specific at all at first.\n",
    "\n",
    "We then use an algorithm called backpropagation (just like we used OLS for regression). Using backpropagation, we optimize these initial weights to make our predictions more accurate.\n",
    "\n",
    "So in summary - for most models, we specify which characteristics we want to look at and optimize.\n",
    "For neural nets, we make the machine \"find out\" which parameters mean what."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08c113-cb4c-4540-8e24-64e36829fbf7",
   "metadata": {},
   "source": [
    "## Building our model\n",
    "The task we are tackling today, is image recognition, which is something that was almost impossible just ten years ago before deep learning had made some more advancements. We are going to be making a classifier model to detect a range of animals.\n",
    "\n",
    "The first thing we are going to do, is to set up our environment. You can do this yourself, running it on your own machine or a Linux server. For this demonstration i am going to be using an online environment, which is probably the easiest.\n",
    "The benefits are both time saving - as their environment comes with all the packages you might need. But they also provide computation on demand! Most services give you a set quota per week, but it is often generous enough for several small projects like this!\n",
    "\n",
    "I choose Kaggle as mine, but Google colab is another excellent option.\n",
    "\n",
    "Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d5136-a1a9-4726-ab1a-a06004137b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ced21-5966-4a53-b76b-ff13d42466fd",
   "metadata": {},
   "source": [
    "First we download and set a path to the kaggle environment for our chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25776f-18ff-4959-abe2-27e4f16584c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "import pathlib\n",
    "import streamlit as st\n",
    "from fastai.vision.all import *\n",
    "from fastai.learner import load_learner\n",
    "from PIL import ImageOps\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0d00b-415c-426e-9d72-905badc6ea38",
   "metadata": {},
   "source": [
    "After we have our imports, we now have our dataset in our environment. The next step, is preparing the data to get loaded into our deep learning model. We are using fast.AI's dataloaders functionality. This provides us with a huge range of functionality for loading our data, but also orchestrates it in away suitable for learning. This is called batching. Here is a sample of the images we have loaded in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5c004-48f2-49d2-9f2e-83add1594a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "dls = dblock.dataloaders(path)\n",
    "\n",
    "# Show a batch of images\n",
    "dls.show_batch(max_n=9, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72053ee-5367-4667-9bda-e05cee5b6577",
   "metadata": {},
   "source": [
    "![The output of our batch](images/batchoutput.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd551da-5d3f-41c9-959a-83db39fc488f",
   "metadata": {},
   "source": [
    "A lot happened here in just 1 line - first, fastAI was able to take the pathobject, containing the path to our files. Then it's converted that into suitable batches which are just about ready for training. Also, dont worry about the italian labels - we can change them later when we actually display our app!\n",
    "\n",
    "Next, we are ready to train our model!\n",
    "\n",
    "What we are going to be doing, is transfer learning. This is a technique in which we take an existing deep learning model that has been pretrained (usually on enormous amounts of data) and then use our dataset to only only train or \"fine tune\" a very small portion of the model - usually the end, which is known as the head of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad94a1-1106-4d89-a369-547bae5c4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90409e2-ec4b-471e-9d18-24ae06135c9a",
   "metadata": {},
   "source": [
    "As variables we input our dataloaders, and then resnet18 - which is a state of the art image recognition model. We then fine-tune for 6 epochs, which are 6 runs throug the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a32d44-43c3-4639-b93b-6ba2703e9ef3",
   "metadata": {},
   "source": [
    "![Training metrics(images/trainingdata.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e6c6a-2c5b-4959-83d7-36dcdfcd63f2",
   "metadata": {},
   "source": [
    "Our model performs exceedingly well, achieving an error rate of 2,44% after just six epochs, corresponding to an overall model accuracy of 97,56%\n",
    "\n",
    "We can check which combinations that the model is having trouble with with a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678f5ab-c90e-4b0d-bf20-fbcb579e5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb310f87-d23d-4dc3-baf2-4f847cc30ef3",
   "metadata": {},
   "source": [
    "![Confusion matrix - the actual labels are on the Y axis, the predictions on the X axis.](images/confusion.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6397d2a-2bc4-424c-a9ea-d262e1709974",
   "metadata": {},
   "source": [
    "This is already really good. We can take a look at what the parts the machine struggled with the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72ebd5-e316-412d-8398-607b68b4ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(8, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db31e3b-e45d-4574-a7b5-b882dea4b1ae",
   "metadata": {},
   "source": [
    "![A plot of the greatest contributors to the loss of our model](images/toplosses.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29407c8-7878-439f-9727-73e4ed3ec979",
   "metadata": {},
   "source": [
    "The image aboce shows what our model predicted is in the image, and the label, followed by the loss, and the probability or how sure the model was of its prediction.\n",
    "\n",
    "As we can see, the very first image it does get wrong, believing it is a butterfly when it is in actuality a spider. However, many of the other top images, are clearly labeled incorrectly. Such as number 2, which is labeled as squirrel, or number 3, which is labeled cow! Even if the dog does look a bit squirrellike if you ask me, mislabelings like this are not helpful, and should really be removed! \n",
    "\n",
    "We can clean our data by manually removing incorrected items like this (or relabeling), or even automated label verification, using another model to authenticate label accuracy!\n",
    "\n",
    "Working with data like this, and ensuring accuracy and precision in what you feed your models, is really the most important part of deep learning, as so many amazing pre-trained models exist already for almost any purpose. \n",
    "\n",
    "With that said, our model is complete and we can export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e6b97-9c15-458a-aeeb-8acffbced0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model export\n",
    "learn.export()\n",
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a479db-8ad0-4028-9f8d-5496f52d88e4",
   "metadata": {},
   "source": [
    "Now we are ready for deployment! If you are like me, and like to see rapid results, there are a great many options for fast deployment of models and python code. We are going to be using streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d87ee7-4b84-4a51-91eb-7f6ce9ccbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "First, we write a short introduction to our app, welcoming visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4ba54-4732-4a26-88da-ede2c800e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble\n",
    "st.title(\"Animal Classifier App\")\n",
    "st.write(\"\"\"\n",
    "This application uses a fine-tuned **ResNet-18** model to classify images into 10 different animal categories. \n",
    "The model has been trained on a dataset of animal images, and it predicts with high confidence for known categories.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e4f39-7caa-4fe8-a19d-d7657e672ef1",
   "metadata": {},
   "source": [
    "Next, we can finally do something about the italian labeling! so we create a simple python dictionary, and use it to map the labels to their corresponding english counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb8c63-aff7-488a-9ff3-499196d32204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the animal categories\n",
    "st.subheader(\"Animal Categories\")\n",
    "name_mapping = {\n",
    "    'cavallo': 'horse',\n",
    "    'pecora': 'sheep',\n",
    "    'elefante': 'elephant',\n",
    "    'gatto': 'cat',\n",
    "    'scoiattolo': 'squirrel',\n",
    "    'gallina': 'chicken',\n",
    "    'ragno': 'spider',\n",
    "    'mucca': 'cow',\n",
    "    'cane': 'dog',\n",
    "    'farfalla': 'butterfly'\n",
    "}\n",
    "st.write(\", \".join([f\"**{v}**\" for v in name_mapping.values()]))\n",
    "st.write(\"\"\"\n",
    "Upload an image of an animal to see the classifier in action!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66366dce-bb5a-4217-b6eb-78751a953b67",
   "metadata": {},
   "source": [
    "Now we import our model, and use streamlits library to make a widget for uploading files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ac828-ef5b-4adf-bb35-e214f6ebc93a",
   "metadata": {},
   "source": [
    "EXPORT_PATH = pathlib.Path(\"model3.pkl\")  # Define the path to your model\n",
    "\n",
    "learn_inf = load_learner(EXPORT_PATH)  # Load the learner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5341c31-233d-4c8d-ace6-2367dc01d92c",
   "metadata": {},
   "source": [
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f0b2d-cd3e-4b6d-9a03-5d07deb2c18f",
   "metadata": {},
   "source": [
    "We are almost there! now all we need to do, is to pass the image into our model and show the predictions. We also do some error handling, to make sure that we only accept images without crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a48957-2ae3-438e-a0f0-1f1fae941b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = None\n",
    "\n",
    "if uploaded_file:\n",
    "    try:\n",
    "        # Read and process the uploaded image\n",
    "        file_bytes = BytesIO(uploaded_file.read())\n",
    "        img = PILImage.create(file_bytes)\n",
    "        img = ImageOps.fit(img, (224, 224))  # Resize if necessary\n",
    "        st.image(img.to_thumb(256, 256), caption=\"Uploaded Image\")\n",
    "\n",
    "        # Make prediction\n",
    "        pred_class, pred_idx, probs = learn_inf.predict(img)\n",
    "        # Map the predicted class to its English label\n",
    "        english_label = name_mapping.get(pred_class, pred_class)  # Fallback to original if not in mapping\n",
    "        st.write(f\"Prediction: {english_label}\")\n",
    "        st.write(f\"Confidence: {probs[pred_idx]:.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error during prediction: {e}\")\n",
    "else:\n",
    "    st.warning(\"Please upload an image to classify.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ac116-0ee1-4df0-8a15-1eb1891569a6",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "You've now made your very own image classifier in a minimum of steps.\n",
    "\n",
    "If you want to host your project, you have to create a github repository, and add your project as a .py file, along with your model and a requirements.txt to handle the dependencies of the project!\n",
    "\n",
    "I have a demonstration live here: https://spvao5wuyengcgcebunrqs.streamlit.app/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
